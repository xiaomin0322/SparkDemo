<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

    <!-- 指定数据冗余份数 -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>

    <!-- 关闭权限检查-->
    <property>
        <name>dfs.permissions.enable</name>
        <value>false</value>
    </property>

    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>

    <property>
        <name>dfs.nameservices</name>
        <value>cluster1</value>
    </property>

    <!-- 集群中NameNode节点都有哪些 -->
    <property>
        <name>dfs.ha.namenodes.cluster1</name>
        <value>nn1,nn2</value>
    </property>

    <!-- nn1的RPC通信地址 -->
    <property>
        <name>dfs.namenode.rpc-address.cluster1.nn1</name>
        <value>udp01:8020</value>
    </property>

    <!-- nn2的RPC通信地址 -->
    <property>
        <name>dfs.namenode.rpc-address.cluster1.nn2</name>
        <value>udp02:8020</value>
    </property>

    <!-- nn1的http通信地址 -->
    <property>
        <name>dfs.namenode.http-address.cluster1.nn1</name>
        <value>udp01:50070</value>
    </property>

    <!-- nn2的http通信地址 -->
    <property>
        <name>dfs.namenode.http-address.cluster1.nn2</name>
        <value>udp02:50070</value>
    </property>

    <!-- 指定NameNode元数据在JournalNode上的存放位置 -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://udp01:8485;udp02:8485;udp03:8485/cluster1</value>
    </property>

    <!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 -->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
    </property>

    <!-- 使用隔离机制时需要ssh无秘钥登录-->
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/hadoop/.ssh/id_rsa</value>
    </property>

    <!-- 声明journalnode服务器存储目录-->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/data/udp/1.0.0.0/hdfs/jnData</value>
    </property>

    <property>
        <name>dfs.client.failover.proxy.provider.cluster1</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>

    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

    <!-- 预留一些，避免把磁盘写满-->
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>104857600</value>
    </property>

    <!-- 读写并发高的时候，避免频繁的读写失败-->
    <property>
        <name>dfs.datanode.max.transfer.threads</name>
        <value>8192</value>
    </property>

    <property>
        <name>dfs.datanode.failed.volumes.tolerated</name>
        <value>0</value>
    </property>

    <property>
        <name>dfs.namenode.heartbeat.recheck-interval</name>
        <value>45000</value>
    </property>

    <property>
        <name>fs.trash.interval</name>
        <value>7320</value>
    </property>

    <property>
        <name>dfs.image.compress</name>
        <value>true</value>
    </property>

    <property>
        <name>dfs.namenode.num.checkpoints.retained</name>
        <value>12</value>
    </property>

    <property>
        <name>dfs.datanode.handler.count</name>
        <value>50</value>
    </property>

    <property>
        <name>dfs.namenode.handler.count</name>
        <value>30</value>
    </property>


    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/data/udp/1.0.0.0/hdfs/dfs/data</value>
    </property>

    <!--    <property>-->
    <!--        <name>dfs.hosts</name>-->
    <!--        <value>/srv/udp/1.0.0.0/hdfs/etc/dfs.include</value>-->
    <!--    </property>-->

    <property>
        <name>dfs.hosts.exclude</name>
        <value>/srv/udp/1.0.0.0/hdfs/etc/hadoop/dfs.exclude</value>
    </property>

    <property>
        <name>dfs.namenode.replication.max-streams</name>
        <value>32</value>
    </property>

    <property>
        <name>dfs.namenode.replication.max-streams-hard-limit</name>
        <value>200</value>
    </property>

    <property>
        <name>dfs.namenode.replication.work.multiplier.per.iteration</name>
        <value>200</value>
    </property>

    <property>
        <name>dfs.datanode.balance.bandwidthPerSec</name>
        <value>10485760</value>
    </property>

</configuration>
